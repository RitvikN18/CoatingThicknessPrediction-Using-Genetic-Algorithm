{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Coatingthickness_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v354lbH5IgrC"
      },
      "source": [
        "**Importing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSt1VqyNHN6Z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import seaborn as sns; sns.set()\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "import copy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import json\n",
        "from keras.utils.conv_utils import convert_kernel\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz_1Ym6OXxhf",
        "outputId": "f1832bf2-af52-446e-8f32-33c8087e413c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwCjp5Sx_eL5"
      },
      "source": [
        "train_df = pd.read_excel(('/content/drive/MyDrive/Train_radarpaint.xlsx'), header = None)\n",
        "test_df = pd.read_excel(('/content/drive/MyDrive/Test_radarpaint.xlsx'), header = None)\n",
        "\n",
        "# Transposing rows to columns\n",
        "train_df = train_df.transpose()\n",
        "test_df = test_df.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aoe9Cb9e9Mzd"
      },
      "source": [
        "# Convert into csv file \n",
        "train_df.to_csv (\"Train.csv\",  \n",
        "                  index = None, \n",
        "                  header=True)\n",
        "\n",
        "test_df.to_csv (\"Test.csv\",  \n",
        "                  index = None, \n",
        "                  header=True)\n",
        "\n",
        "test = pd.DataFrame(pd.read_csv(\"Test.csv\")) \n",
        "train = pd.DataFrame(pd.read_csv(\"Train.csv\")) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdNaxxsLHCv"
      },
      "source": [
        "**Splitting the dataset into attributes (X) and labels (y)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHWlU1ALLK2W"
      },
      "source": [
        "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1:]\n",
        "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa9e4kQ5_FuB"
      },
      "source": [
        "# 10,000 columns is very high lets reduce this using \n",
        "# Dimensionality Reduction using PCA \n",
        "\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 5)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqCN63msA8WE"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8fX52_LB7us"
      },
      "source": [
        "inputs = np.array(X_train)\n",
        "targets = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2NpaCgVgXXG"
      },
      "source": [
        "num_components = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgbqJf4AhPuP"
      },
      "source": [
        "chromosome_length = num_components*11 + 11 + 11*833 + 833+ 833*1 + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgvqVXGfFkB"
      },
      "source": [
        "chromosomes = np.random.uniform(-1, 1, (1, chromosome_length))\n",
        "i=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edZv17sajegE"
      },
      "source": [
        "# NEW MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMyAMe1Od7Di",
        "outputId": "2138b9e4-09e7-45ce-c4d3-c715adea4e23"
      },
      "source": [
        "zero_weights = copy.deepcopy(chromosomes[i-1][:55])\n",
        "zero_weights = zero_weights.reshape(5, 11)\n",
        "zero_bias = copy.deepcopy(chromosomes[i-1][55:66])\n",
        "zero_bias = zero_bias.reshape(11, )\n",
        "one_weights = copy.deepcopy(chromosomes[i-1][66:9229])\n",
        "one_weights = one_weights.reshape(11, 833)\n",
        "one_bias = copy.deepcopy(chromosomes[i-1][9229:10062])\n",
        "one_bias = one_bias.reshape(833, )\n",
        "two_weights = copy.deepcopy(chromosomes[i-1][10062:10895])\n",
        "two_weights = two_weights.reshape(833, 1)\n",
        "two_bias = copy.deepcopy(chromosomes[i-1][10895])\n",
        "two_bias = two_bias.reshape(1, )\n",
        "# Define Model\n",
        "model = keras.Sequential([layers.Dense(11, activation = 'relu', weights=[zero_weights, zero_bias], kernel_initializer=None, bias_initializer=None),  \n",
        "                                      layers.Dense(833, activation = 'relu', weights=[one_weights, one_bias], kernel_initializer=None, bias_initializer=None),\n",
        "                                      layers.Dense(1, weights=[two_weights, two_bias], kernel_initializer=None, bias_initializer=None)])\n",
        "# Compile Model\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.01),loss='mse')\n",
        "model.fit(inputs, targets, epochs=100, batch_size=150, shuffle=False)\n",
        "weights = model.get_weights() \n",
        "prediction_test = model.predict(X_test)\n",
        "mse=mean_squared_error(prediction_test,y_test)\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4817539.0156\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 145445641.0000\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 13827010.3750\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 34876965.5000\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 774861.6250\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 7082070.5625\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2186118.9062\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 669203.3789\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 850153.1602\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 65645.0967\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 256087.3887\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 16225.8724\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 48150.7864\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 16587.2144\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 7920.0643\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 7230.4289\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2999.7515\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3339.0148\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 13696.8663\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 19661.5493\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 14958.4262\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3485.8663\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2439.7518\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3553.9763\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2956.9491\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2790.7262\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2186.4383\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2129.3518\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1929.2371\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1905.7918\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1818.3648\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1782.7249\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1716.4548\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1686.8697\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1620.8038\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1609.2341\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1533.2192\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1574.8291\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1492.5226\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1781.0845\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1991.4538\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4111.9365\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 8748.0706\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 27819.6185\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 72324.9951\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 192138.2002\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 380156.7012\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 729911.5312\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1110997.6094\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1683968.8359\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2063677.6719\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2422823.3281\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2458073.1562\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2448219.7031\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2099102.5312\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1708261.4766\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1187565.5234\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 768083.6758\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 489044.1562\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 334023.8535\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 276921.9863\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 322141.2969\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 334260.9805\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 314992.0801\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 281268.8457\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 264969.0137\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 253053.5801\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 265877.3438\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 285718.5762\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 337378.4121\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 404827.7734\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 526242.2422\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 687518.5312\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 952990.5469\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1301221.3594\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1826598.2969\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2422696.4844\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3124321.2188\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3524618.1875\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3520856.1250\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2721352.6406\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1615080.7812\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 621766.9453\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 130464.5835\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 4902.3122\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 12150.3894\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 24581.0652\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 18746.3982\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 10472.1818\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 3724.0035\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1385.3503\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 539.2413\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 470.7130\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 548.4437\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 473.3726\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 502.6831\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 390.8597\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 402.3360\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 327.6745\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 354.9768\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f72625f0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "397.47119937162785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txn7FV7DA727"
      },
      "source": [
        "class Genetic:\n",
        "    ''' \n",
        "        If this function is called without passing any arguments, then an initial random chromosomes and fitness values are generated.\n",
        "        Else if the function is called by passing the chromosomes and fitness values as arguments, then the passed values will be stored in \n",
        "        the class variables. The chromosomes and fitness values that are passed to this function are loaded from the google drive\n",
        "     '''\n",
        "    def __init__(self, chromosomes = np.random.uniform(-1, 1, (12, 115)), tot_fitness=np.zeros((12))):\n",
        "        self.chromosomes = chromosomes\n",
        "        self.tot_fitness = tot_fitness\n",
        "        self.num_chromosomes = 12\n",
        "\n",
        "\n",
        "    ''' \n",
        "        When this function is called, this function first initializes a temporary variable (cur_fitness) to store \n",
        "        the fitness values calculated in this function.\n",
        "        A for loop is run 12 times(number of chromosomes in a generation)\n",
        "        And in each iteration of the for loop, the function fits the model for train dataset using the weights of that chromosome and\n",
        "        calculates the MSE for the test dataset for the trained model. All the MSE values of each chromosome are stored in the cur_fitness variable.\n",
        "        This cur_fitness variable is copied to the tot_fitness variable, and these fitness values are returned.\n",
        "    '''\n",
        "    def cal_fitness(self):\n",
        "        cur_fitness = np.zeros((self.num_chromosomes))\n",
        "        for i in range(1, self.chromosomes.shape[0]+1):\n",
        "            zero_weights = copy.deepcopy(self.chromosomes[i-1][:25])\n",
        "            zero_weights = zero_weights.reshape(5, 5)\n",
        "            zero_bias = copy.deepcopy(self.chromosomes[i-1][25:30])\n",
        "            zero_bias = zero_bias.reshape(5, )\n",
        "            one_weights = copy.deepcopy(self.chromosomes[i-1][30:90])\n",
        "            one_weights = one_weights.reshape(5, 12)\n",
        "            one_bias = copy.deepcopy(self.chromosomes[i-1][90:102])\n",
        "            one_bias = one_bias.reshape(12, )\n",
        "            two_weights = copy.deepcopy(self.chromosomes[i-1][102:114])\n",
        "            two_weights = two_weights.reshape(12, 1)\n",
        "            two_bias = copy.deepcopy(self.chromosomes[i-1][114])\n",
        "            two_bias = two_bias.reshape(1, )\n",
        "            # Define Model\n",
        "            model = keras.Sequential([layers.Dense(5, activation = 'sigmoid', weights=[zero_weights, zero_bias], kernel_initializer=None, bias_initializer=None),  \n",
        "                                      layers.Dense(12, activation = 'sigmoid', weights=[one_weights, one_bias], kernel_initializer=None, bias_initializer=None),\n",
        "                                      layers.Dense(1, weights=[two_weights, two_bias], kernel_initializer=None, bias_initializer=None)])\n",
        "            # Compile Model\n",
        "            model.compile(loss='mse',optimizer=keras.optimizers.RMSprop(learning_rate=0.008),metrics=['mse'])\n",
        "            model.fit(inputs, targets, epochs=100, batch_size=8, shuffle=False)\n",
        "            prediction_test = model.predict(X_test)\n",
        "            mse=mean_squared_error(prediction_test,y_test)\n",
        "            cur_fitness[i-1] = mse\n",
        "        self.tot_fitness = copy.deepcopy(cur_fitness)\n",
        "        return cur_fitness #send to selection\n",
        "\n",
        "\n",
        "    ''' \n",
        "        cur_fitness (which is returned by the above function) is passed as an argument to this function.\n",
        "        A dictionary named \"selected\" is initialized. A temporary variable (temp) is created by copying cur_fitness variable.\n",
        "        The temp variable is sorted (this is done because after sorting the first element is the one with least\n",
        "        fitness value[MSE], so that would be the best particle of this generation && the last element is the one with the \n",
        "        highest fitness value[MSE], so that element would be the worst particle). Then the 6 best particles are chosen as \n",
        "        parents. The 3 worst particles are chosen to be replaced. The indeces of these selected particles are stored in the \n",
        "        \"selected\"(name of the dictionary) dictionary. This dictionary is returned.\n",
        "    '''\n",
        "    def selection(self, cur_fitness):\n",
        "        selected = {}\n",
        "        temp = copy.deepcopy(cur_fitness)\n",
        "        temp = np.sort(temp)\n",
        "        p1, = np.where(cur_fitness == temp[0])\n",
        "        p2, = np.where(cur_fitness == temp[1])\n",
        "        p3, = np.where(cur_fitness == temp[2])\n",
        "        p4, = np.where(cur_fitness == temp[3])\n",
        "        p5, = np.where(cur_fitness == temp[4])\n",
        "        p6, = np.where(cur_fitness == temp[5])\n",
        "        bad1, = np.where(cur_fitness == temp[11])\n",
        "        bad2, = np.where(cur_fitness == temp[10])\n",
        "        bad3, = np.where(cur_fitness == temp[9])\n",
        "        selected[\"p1\"] = [p1[0], p2[0]]\n",
        "        selected[\"p2\"] = [p3[0], p4[0]]\n",
        "        selected[\"p3\"] = [p5[0], p6[0]]\n",
        "        selected[\"bad\"] = [bad1[0], bad2[0], bad3[0]]\n",
        "        return selected #send to crossover\n",
        "\n",
        "\n",
        "    ''' \n",
        "        \"selected\" and cur_fitness (which were returned by the above functions) are passed as arguments to this function.\n",
        "        The variables are initialized (child1, child2 & child3) to store the newly generated children.\n",
        "        6 Parent variables are loaded from the \"selected\" dictionary.\n",
        "        Since the length of each chromosome is 85, we iterate a for loop 85 times, \n",
        "        and each time, if we randomly choose a prob which is either 0 or 1, \n",
        "        and if the prob is 0, then odd number parent's chromosome is copied to the child.\n",
        "        If the prob is 1, then the even numbered parent's chromomsome is copied to the child.\n",
        "        After these children are generated, these children replace the 3 bad chromosomes.\n",
        "    ''' \n",
        "    def crossover(self, selected, cur_fitness):\n",
        "        child1 = np.zeros(115)\n",
        "        child2 = np.zeros(115)\n",
        "        child3 = np.zeros(115)\n",
        "        parent1 = self.chromosomes[selected[\"p1\"][0]]\n",
        "        parent2 = self.chromosomes[selected[\"p1\"][1]]\n",
        "        parent3 = self.chromosomes[selected[\"p2\"][0]]\n",
        "        parent4 = self.chromosomes[selected[\"p2\"][1]]\n",
        "        parent5 = self.chromosomes[selected[\"p3\"][0]]\n",
        "        parent6 = self.chromosomes[selected[\"p3\"][1]]\n",
        "        prob = np.random.randint(0, 2, (115))\n",
        "        for i in range(115):\n",
        "            if prob[i] == 0:\n",
        "                child1[i] = parent1[i]\n",
        "                child2[i] = parent3[i]\n",
        "                child3[i] = parent5[i]\n",
        "            else:\n",
        "                child1[i] = parent2[i]\n",
        "                child2[i] = parent4[i]\n",
        "                child3[i] = parent6[i]\n",
        "        self.chromosomes[selected[\"bad\"][0], :] = child1[:] \n",
        "        self.chromosomes[selected[\"bad\"][1], :] = child2[:]\n",
        "        self.chromosomes[selected[\"bad\"][2], :] = child3[:]\n",
        "        return  #send to mutation\n",
        "    \n",
        "    ''' \n",
        "        In this function, we randomly choose 10% of the chromosomes to be changed. And the new value in the chromosome \n",
        "        is chosen by using a gaussian distribution with (mean = value of that chromosome) and (standard deviation = 0)\n",
        "    ''' \n",
        "    def mutation(self):\n",
        "        for i in range(self.num_chromosomes):\n",
        "            gene = self.chromosomes[i]\n",
        "            if random.uniform(0.00, 1.00) <= 0.1:\n",
        "                gene = random.gauss(mu=gene, sigma=0)\n",
        "            self.chromosomes[i][:] = gene\n",
        "        return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qULFby_p8J_S",
        "outputId": "b63febf3-7113-4921-c06d-3d5954d8ea75"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "num_generations = 10\n",
        "genetic = Genetic()\n",
        "for i in range(num_generations):\n",
        "    print(\"Generation: \", i)\n",
        "    cur_fitness = genetic.cal_fitness()\n",
        "    print(cur_fitness)\n",
        "    selected = genetic.selection(cur_fitness)\n",
        "    print(\"\\n\")\n",
        "    print(selected)\n",
        "    genetic.crossover(selected, cur_fitness)\n",
        "    genetic.mutation()\n",
        "    print(\"\\n\")\n",
        "    print(genetic.tot_fitness)\n",
        "    np.save('/content/drive/MyDrive/' + str(i) + '_chromosomes', genetic.chromosomes)\n",
        "    np.save('/content/drive/MyDrive/' + str(i) + '_tot_fitness', genetic.tot_fitness)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1122 - mse: 0.1122\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0444\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd07564b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 3.7346 - mse: 3.7346WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0145s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1418 - mse: 0.1418\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1000 - mse: 0.1000\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1011 - mse: 0.1011\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0719 - mse: 0.0719\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0784 - mse: 0.0784\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0838 - mse: 0.0838\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0397\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0786 - mse: 0.0786\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0839 - mse: 0.0839\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0823 - mse: 0.0823\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1633 - mse: 0.1633\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0794\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1116 - mse: 0.1116\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1148 - mse: 0.1148\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0911 - mse: 0.0911\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0787 - mse: 0.0787\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0989 - mse: 0.0989\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0787 - mse: 0.0787\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0758d5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0969\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0777 - mse: 0.0777\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0890 - mse: 0.0890\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1234 - mse: 0.1234\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0838 - mse: 0.0838\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0708 - mse: 0.0708\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.1136\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0705 - mse: 0.0705\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd075520e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0035 - mse: 0.0035\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1119 - mse: 0.1119\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0644 - mse: 0.0644\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0733\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0748 - mse: 0.0748\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0738 - mse: 0.0738\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0474 - mse: 0.0474\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0798 - mse: 0.0798\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd077be9ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1484 - mse: 0.1484\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0886 - mse: 0.0886\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0972\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0935 - mse: 0.0935\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0799 - mse: 0.0799\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0904 - mse: 0.0904\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0850 - mse: 0.0850\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0773 - mse: 0.0773\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0477 - mse: 0.0477\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1072 - mse: 0.1072\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0927\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd074505510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2207 - mse: 0.2207\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0818 - mse: 0.0818\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0848 - mse: 0.0848\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0741\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0732\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0767 - mse: 0.0767\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0742a6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0750\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0739 - mse: 0.0739\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0912\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0884 - mse: 0.0884\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1865 - mse: 0.1865\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0964\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0732\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0736 - mse: 0.0736\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0793 - mse: 0.0793\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd075eed400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1731 - mse: 0.1731\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0946 - mse: 0.0946\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0778 - mse: 0.0778\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0976 - mse: 0.0976\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0813 - mse: 0.0813\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0827 - mse: 0.0827\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0768 - mse: 0.0768\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0749 - mse: 0.0749\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1108 - mse: 0.1108\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd083497268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0821 - mse: 0.0821\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0741\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0759 - mse: 0.0759\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1087 - mse: 0.1087\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0422\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0874\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd07fa94620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0804 - mse: 0.0804\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0896 - mse: 0.0896\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0919\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1068 - mse: 0.1068\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1210 - mse: 0.1210\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0950 - mse: 0.0950\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0760 - mse: 0.0760\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0915\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0737 - mse: 0.0737\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0974 - mse: 0.0974\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd07666ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0069 - mse: 0.0069\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0804 - mse: 0.0804\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0902 - mse: 0.0902\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1014 - mse: 0.1014\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0728 - mse: 0.0728\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0584 - mse: 0.0584\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0743 - mse: 0.0743\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0934 - mse: 0.0934\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0777 - mse: 0.0777\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1414 - mse: 0.1414\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0772 - mse: 0.0772\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0756 - mse: 0.0756\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0800 - mse: 0.0800\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0775a9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.88178549 0.82607189 0.85147929 0.85943612 0.88898463 0.84522156\n",
            " 0.85695808 0.82062445 0.85838594 0.84599399 0.86409968 0.88299886]\n",
            "\n",
            "\n",
            "{'p1': [7, 1], 'p2': [5, 9], 'p3': [2, 6], 'bad': [4, 11, 0]}\n",
            "\n",
            "\n",
            "[0.88178549 0.82607189 0.85147929 0.85943612 0.88898463 0.84522156\n",
            " 0.85695808 0.82062445 0.85838594 0.84599399 0.86409968 0.88299886]\n",
            "Generation:  5\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 1.2339 - mse: 1.2339WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0059s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0853 - mse: 0.0853\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0794\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0859 - mse: 0.0859\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0924 - mse: 0.0924\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0777 - mse: 0.0777\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0726\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0787 - mse: 0.0787\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0584 - mse: 0.0584\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0775a9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0816 - mse: 0.0816\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0952\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.1136\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1077 - mse: 0.1077\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1122 - mse: 0.1122\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0444\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0775a9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1418 - mse: 0.1418\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1000 - mse: 0.1000\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1011 - mse: 0.1011\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0719 - mse: 0.0719\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0784 - mse: 0.0784\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0838 - mse: 0.0838\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0786 - mse: 0.0786\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0839 - mse: 0.0839\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0823 - mse: 0.0823\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0360\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1633 - mse: 0.1633\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0794\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1116 - mse: 0.1116\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1148 - mse: 0.1148\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0911 - mse: 0.0911\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0787 - mse: 0.0787\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0989 - mse: 0.0989\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0787 - mse: 0.0787\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd074466c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0969\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0777 - mse: 0.0777\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0890 - mse: 0.0890\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1234 - mse: 0.1234\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0838 - mse: 0.0838\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0708 - mse: 0.0708\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.1136\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0705 - mse: 0.0705\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0825b4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 0.6152 - mse: 0.6152WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0894 - mse: 0.0894\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0819 - mse: 0.0819\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0834 - mse: 0.0834\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0895 - mse: 0.0895\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0955 - mse: 0.0955\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0936 - mse: 0.0936\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0913 - mse: 0.0913\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0932 - mse: 0.0932\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1122 - mse: 0.1122\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0778 - mse: 0.0778\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0766 - mse: 0.0766\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0770 - mse: 0.0770\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0791 - mse: 0.0791\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0822 - mse: 0.0822\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0811 - mse: 0.0811\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1477 - mse: 0.1477\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1138 - mse: 0.1138\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1053 - mse: 0.1053\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0790 - mse: 0.0790\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0796 - mse: 0.0796\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0956 - mse: 0.0956\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0798 - mse: 0.0798\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0855 - mse: 0.0855\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0775a9048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1484 - mse: 0.1484\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0886 - mse: 0.0886\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0972\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0935 - mse: 0.0935\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0799 - mse: 0.0799\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0904 - mse: 0.0904\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0850 - mse: 0.0850\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0773 - mse: 0.0773\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1072 - mse: 0.1072\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0927\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0835b9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.2207 - mse: 0.2207\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0818 - mse: 0.0818\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0848 - mse: 0.0848\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0741\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0732\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0767 - mse: 0.0767\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd07d23c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 1.1631 - mse: 1.1631WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0750\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0739 - mse: 0.0739\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0912\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0884 - mse: 0.0884\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1865 - mse: 0.1865\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0964\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0732\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0736 - mse: 0.0736\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0793 - mse: 0.0793\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd076c0b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1731 - mse: 0.1731\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0946\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0778 - mse: 0.0778\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0976 - mse: 0.0976\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0813 - mse: 0.0813\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0827 - mse: 0.0827\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0768 - mse: 0.0768\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0749 - mse: 0.0749\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1108 - mse: 0.1108\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd081a48488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0821 - mse: 0.0821\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0741\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0759 - mse: 0.0759\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1087 - mse: 0.1087\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0422\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0874\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0744fa1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0804 - mse: 0.0804\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0896 - mse: 0.0896\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0919\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1068 - mse: 0.1068\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1210 - mse: 0.1210\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0950 - mse: 0.0950\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0760 - mse: 0.0760\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0915\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0737 - mse: 0.0737\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0247\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0974 - mse: 0.0974\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd07ad1e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 3.7600 - mse: 3.7600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0110s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1483 - mse: 0.1483\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0883\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0876 - mse: 0.0876\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0406\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0474 - mse: 0.0474\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1186 - mse: 0.1186\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0810 - mse: 0.0810\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0743 - mse: 0.0743\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0644 - mse: 0.0644\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0747 - mse: 0.0747\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0848 - mse: 0.0848\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd074c7d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.8807873  0.82607189 0.85147929 0.85943612 0.83863272 0.84522156\n",
            " 0.85695808 0.82062445 0.85838594 0.84599399 0.86409968 0.87746138]\n",
            "\n",
            "\n",
            "{'p1': [7, 1], 'p2': [4, 5], 'p3': [9, 2], 'bad': [0, 11, 10]}\n",
            "\n",
            "\n",
            "[0.8807873  0.82607189 0.85147929 0.85943612 0.83863272 0.84522156\n",
            " 0.85695808 0.82062445 0.85838594 0.84599399 0.86409968 0.87746138]\n",
            "Generation:  6\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1079 - mse: 0.1079\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0858 - mse: 0.0858\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0910 - mse: 0.0910\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0931 - mse: 0.0931\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0406\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0775a9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 0.4839 - mse: 0.4839WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0082s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0825 - mse: 0.0825\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0816 - mse: 0.0816\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0952\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.1136\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1077 - mse: 0.1077\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1122 - mse: 0.1122\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0444\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd074c7d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 3.7346 - mse: 3.7346WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0099s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1418 - mse: 0.1418\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1000 - mse: 0.1000\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1011 - mse: 0.1011\n",
            "Epoch 7/100\n",
            "127/129 [============================>.] - ETA: 0s - loss: 0.0847 - mse: 0.0847Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57z4ALoWDeK"
      },
      "source": [
        "chromosomes = np.load('/content/drive/MyDrive/25_chromosomes.npy')\n",
        "tot_fitness = np.load('/content/drive/MyDrive/25_tot_fitness.npy')\n",
        "genetic = Genetic(chromosomes = chromosomes, tot_fitness=tot_fitness)\n",
        "num_generations = 500\n",
        "for i in range(32, num_generations):\n",
        "    print(\"Generation: \", i+1)\n",
        "    cur_fitness = genetic.cal_fitness()\n",
        "    selected = genetic.selection(cur_fitness)\n",
        "    genetic.crossover(selected, cur_fitness)\n",
        "    genetic.mutation()\n",
        "    np.save('/content/drive/MyDrive/' + str(i) + '_chromosomes', genetic.chromosomes)\n",
        "    np.save('/content/drive/MyDrive/' + str(i) + '_tot_fitness', genetic.tot_fitness)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs3vy57LY8bg",
        "outputId": "43396853-f7a5-4acb-b955-cd210296e121"
      },
      "source": [
        "chromosomes = np.load('/content/drive/MyDrive/999_chromosomes.npy')\n",
        "tot_fitness = np.load('/content/drive/MyDrive/999_tot_fitness.npy')\n",
        "#minInd = np.argmin(tot_fitness)\n",
        "for minInd in range(12):\n",
        "    print(minInd)\n",
        "    i = minInd\n",
        "    zero_weights = copy.deepcopy(chromosomes[i-1][:25])\n",
        "    zero_weights = zero_weights.reshape(5, 5)\n",
        "    zero_bias = copy.deepcopy(chromosomes[i-1][25:30])\n",
        "    zero_bias = zero_bias.reshape(5, )\n",
        "    one_weights = copy.deepcopy(chromosomes[i-1][30:90])\n",
        "    one_weights = one_weights.reshape(5, 12)\n",
        "    one_bias = copy.deepcopy(chromosomes[i-1][90:102])\n",
        "    one_bias = one_bias.reshape(12, )\n",
        "    two_weights = copy.deepcopy(chromosomes[i-1][102:114])\n",
        "    two_weights = two_weights.reshape(12, 1)\n",
        "    two_bias = copy.deepcopy(chromosomes[i-1][114])\n",
        "    two_bias = two_bias.reshape(1, )\n",
        "    # Define Model\n",
        "    model = keras.Sequential([layers.Dense(5, activation = 'sigmoid', weights=[zero_weights, zero_bias], kernel_initializer=None, bias_initializer=None),  \n",
        "                                      layers.Dense(12, activation = 'sigmoid', weights=[one_weights, one_bias], kernel_initializer=None, bias_initializer=None),\n",
        "                                      layers.Dense(1, weights=[two_weights, two_bias], kernel_initializer=None, bias_initializer=None)])\n",
        "    # Compile Model\n",
        "    model.compile(loss='mse',optimizer=keras.optimizers.RMSprop(learning_rate=0.008),metrics=['mse'])\n",
        "    model.fit(inputs, targets, epochs=100, batch_size=8, shuffle=False)\n",
        "    prediction_test = model.predict(X_test)\n",
        "    mse=mean_squared_error(prediction_test,y_test)\n",
        "    tot_fitness[minInd] = mse\n",
        "    print(mse)\n",
        "minInd = np.argmin(tot_fitness)\n",
        "print(tot_fitness[minInd])\n",
        "if 1:\n",
        "    zero_weights = copy.deepcopy(chromosomes[i-1][:25])\n",
        "    zero_weights = zero_weights.reshape(5, 5)\n",
        "    zero_bias = copy.deepcopy(chromosomes[i-1][25:30])\n",
        "    zero_bias = zero_bias.reshape(5, )\n",
        "    one_weights = copy.deepcopy(chromosomes[i-1][30:90])\n",
        "    one_weights = one_weights.reshape(5, 12)\n",
        "    one_bias = copy.deepcopy(chromosomes[i-1][90:102])\n",
        "    one_bias = one_bias.reshape(12, )\n",
        "    two_weights = copy.deepcopy(chromosomes[i-1][102:114])\n",
        "    two_weights = two_weights.reshape(12, 1)\n",
        "    two_bias = copy.deepcopy(chromosomes[i-1][114])\n",
        "    two_bias = two_bias.reshape(1, )\n",
        "    # Define Model\n",
        "    model = keras.Sequential([layers.Dense(5, activation = 'sigmoid', weights=[zero_weights, zero_bias], kernel_initializer=None, bias_initializer=None),  \n",
        "                                      layers.Dense(12, activation = 'sigmoid', weights=[one_weights, one_bias], kernel_initializer=None, bias_initializer=None),\n",
        "                                      layers.Dense(1, weights=[two_weights, two_bias], kernel_initializer=None, bias_initializer=None)])\n",
        "    # Compile Model\n",
        "    model.compile(loss='mse',optimizer=keras.optimizers.Adam(learning_rate=0.008),metrics=['mse'])\n",
        "    model.fit(inputs, targets, epochs=100, batch_size=8, shuffle=False)\n",
        "    prediction_test = model.predict(X_test)\n",
        "    mse=mean_squared_error(prediction_test,y_test)\n",
        "    print(\"Best MSE is: \", mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0708 - mse: 0.0708\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0687\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0700 - mse: 0.0700\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0703 - mse: 0.0703\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0676\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0744 - mse: 0.0744\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0733 - mse: 0.0733\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0763 - mse: 0.0763\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0658\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0644 - mse: 0.0644\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c41431e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8954291243139934\n",
            "1\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1183 - mse: 0.1183\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0690 - mse: 0.0690\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0787 - mse: 0.0787\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0806 - mse: 0.0806\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0795 - mse: 0.0795\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0791 - mse: 0.0791\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0683\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0683\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0614\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0552\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0641\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c2e5d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8867247864751217\n",
            "2\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1182 - mse: 0.1182\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0703 - mse: 0.0703\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0683\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0715 - mse: 0.0715\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0784 - mse: 0.0784\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0728 - mse: 0.0728\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0766\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0763 - mse: 0.0763\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0559\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0533\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0629\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c44d5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.9502191205668946\n",
            "3\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1188 - mse: 0.1188\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0726 - mse: 0.0726\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0738 - mse: 0.0738\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0763 - mse: 0.0763\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0766\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0738 - mse: 0.0738\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0756 - mse: 0.0756\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0769\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0755\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0756 - mse: 0.0756\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0688\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0698 - mse: 0.0698\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0684 - mse: 0.0684\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 1s 6ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0613\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0564\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0453\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0485\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0488\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0491\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c5b4b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8879794412756187\n",
            "4\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1182 - mse: 0.1182\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0700 - mse: 0.0700\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0682 - mse: 0.0682\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0748\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0756 - mse: 0.0756\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0772 - mse: 0.0772\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0765 - mse: 0.0765\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0753 - mse: 0.0753\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0782 - mse: 0.0782\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0769\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0736 - mse: 0.0736\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0705 - mse: 0.0705\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0660\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0648 - mse: 0.0648\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0644 - mse: 0.0644\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0659\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0532\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0482 - mse: 0.0482\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16cae006a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.922437289445531\n",
            "5\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1183 - mse: 0.1183\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0686\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0693\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0690 - mse: 0.0690\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0726 - mse: 0.0726\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0732 - mse: 0.0732\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0705 - mse: 0.0705\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0737\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0741 - mse: 0.0741\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0742 - mse: 0.0742\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0742 - mse: 0.0742\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0703 - mse: 0.0703\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0749 - mse: 0.0749\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0733 - mse: 0.0733\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0567\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0556\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0577\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0486\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c4e7c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8862626427938446\n",
            "6\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1198 - mse: 0.1198\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0689 - mse: 0.0689\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0716 - mse: 0.0716\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0744 - mse: 0.0744\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0715 - mse: 0.0715\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0747 - mse: 0.0747\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0757\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0708 - mse: 0.0708\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0765 - mse: 0.0765\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0787 - mse: 0.0787\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0788 - mse: 0.0788\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0729\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0756 - mse: 0.0756\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0664\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0671 - mse: 0.0671\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0619 - mse: 0.0619\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0551\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0504\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c593d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.930472509810557\n",
            "7\n",
            "Epoch 1/100\n",
            "  1/129 [..............................] - ETA: 0s - loss: 0.1113 - mse: 0.1113WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0104s). Check your callbacks.\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.1187\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0687\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0728 - mse: 0.0728\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0748 - mse: 0.0748\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0750 - mse: 0.0750\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0737\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0758\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0810 - mse: 0.0810\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0765 - mse: 0.0765\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0737\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0704\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0669 - mse: 0.0669\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0666\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0573\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0473\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0479\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0492 - mse: 0.0492\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c96d51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.9590178836007686\n",
            "8\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1180 - mse: 0.1180\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0725\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0772 - mse: 0.0772\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0681\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0754 - mse: 0.0754\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0693\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0771 - mse: 0.0771\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0749 - mse: 0.0749\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0731\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0745 - mse: 0.0745\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0744 - mse: 0.0744\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0584\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0580\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0686\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0684 - mse: 0.0684\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0537\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0565\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c4001ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8694140878426107\n",
            "9\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1201 - mse: 0.1201\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0739 - mse: 0.0739\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0715 - mse: 0.0715\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0750 - mse: 0.0750\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0691\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0676\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0654\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0761 - mse: 0.0761\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0755\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0742 - mse: 0.0742\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0726 - mse: 0.0726\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0600\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0584\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0611 - mse: 0.0611\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0695\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0538 - mse: 0.0538\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0550\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16ce542ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8847221529920881\n",
            "10\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1201 - mse: 0.1201\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0712\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0692 - mse: 0.0692\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0726\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0730\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0755\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0698 - mse: 0.0698\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0686\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0674\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0694\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0754 - mse: 0.0754\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0687\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0693\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0723\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0786 - mse: 0.0786\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0707\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0747 - mse: 0.0747\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0759 - mse: 0.0759\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0665 - mse: 0.0665\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0586\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0584\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0602\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0649\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0621\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0633\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0655 - mse: 0.0655\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0632\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0593\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0540\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0530 - mse: 0.0530\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0521 - mse: 0.0521\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0578\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0534\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0543 - mse: 0.0543\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16ce542d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8819747524413322\n",
            "11\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.1183 - mse: 0.1183\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0698 - mse: 0.0698\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0722\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0706\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0710\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0713 - mse: 0.0713\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0758\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0733 - mse: 0.0733\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0697 - mse: 0.0697\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0792 - mse: 0.0792\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0762 - mse: 0.0762\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0777 - mse: 0.0777\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0736 - mse: 0.0736\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0748\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0608\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0679 - mse: 0.0679\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0662\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0639 - mse: 0.0639\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0614\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0594\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0643\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0626 - mse: 0.0626\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0616 - mse: 0.0616\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0599\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0561\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0612\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0555\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0483 - mse: 0.0483\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0496 - mse: 0.0496\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0536\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0448\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.0474 - mse: 0.0474\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0623\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1432 - mse: 0.1432\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1055 - mse: 0.1055\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c78d1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.8620262875452359\n",
            "0.8620262875452359\n",
            "Epoch 1/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080\n",
            "Epoch 2/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1767 - mse: 0.1767\n",
            "Epoch 3/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2087 - mse: 0.2087\n",
            "Epoch 4/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2818 - mse: 0.2818\n",
            "Epoch 5/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.3437 - mse: 0.3437\n",
            "Epoch 6/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.3481 - mse: 0.3481\n",
            "Epoch 7/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.3594 - mse: 0.3594\n",
            "Epoch 8/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2800 - mse: 0.2800\n",
            "Epoch 9/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.3621 - mse: 0.3621\n",
            "Epoch 10/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2831 - mse: 0.2831\n",
            "Epoch 11/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2798 - mse: 0.2798\n",
            "Epoch 12/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2937 - mse: 0.2937\n",
            "Epoch 13/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2714 - mse: 0.2714\n",
            "Epoch 14/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2789 - mse: 0.2789\n",
            "Epoch 15/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2726 - mse: 0.2726\n",
            "Epoch 16/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2623 - mse: 0.2623\n",
            "Epoch 17/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2626 - mse: 0.2626\n",
            "Epoch 18/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2521 - mse: 0.2521\n",
            "Epoch 19/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2453 - mse: 0.2453\n",
            "Epoch 20/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2378 - mse: 0.2378\n",
            "Epoch 21/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2359 - mse: 0.2359\n",
            "Epoch 22/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2325 - mse: 0.2325\n",
            "Epoch 23/100\n",
            "129/129 [==============================] - 0s 3ms/step - loss: 0.2278 - mse: 0.2278\n",
            "Epoch 24/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2231 - mse: 0.2231\n",
            "Epoch 25/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1917 - mse: 0.1917\n",
            "Epoch 26/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1981 - mse: 0.1981\n",
            "Epoch 27/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1830 - mse: 0.1830\n",
            "Epoch 28/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2026 - mse: 0.2026\n",
            "Epoch 29/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1488 - mse: 0.1488\n",
            "Epoch 30/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2123 - mse: 0.2123\n",
            "Epoch 31/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2095 - mse: 0.2095\n",
            "Epoch 32/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2185 - mse: 0.2185\n",
            "Epoch 33/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1707 - mse: 0.1707\n",
            "Epoch 34/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2035 - mse: 0.2035\n",
            "Epoch 35/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2045 - mse: 0.2045\n",
            "Epoch 36/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2043 - mse: 0.2043\n",
            "Epoch 37/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2118 - mse: 0.2118\n",
            "Epoch 38/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1647 - mse: 0.1647\n",
            "Epoch 39/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1957 - mse: 0.1957\n",
            "Epoch 40/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1861 - mse: 0.1861\n",
            "Epoch 41/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1959 - mse: 0.1959\n",
            "Epoch 42/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1833 - mse: 0.1833\n",
            "Epoch 43/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1852 - mse: 0.1852\n",
            "Epoch 44/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1896 - mse: 0.1896\n",
            "Epoch 45/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1861 - mse: 0.1861\n",
            "Epoch 46/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1833 - mse: 0.1833\n",
            "Epoch 47/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1891 - mse: 0.1891\n",
            "Epoch 48/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1833 - mse: 0.1833\n",
            "Epoch 49/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1880 - mse: 0.1880\n",
            "Epoch 50/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1886 - mse: 0.1886\n",
            "Epoch 51/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1844 - mse: 0.1844\n",
            "Epoch 52/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1873 - mse: 0.1873\n",
            "Epoch 53/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1865 - mse: 0.1865\n",
            "Epoch 54/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1870 - mse: 0.1870\n",
            "Epoch 55/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1863 - mse: 0.1863\n",
            "Epoch 56/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1870 - mse: 0.1870\n",
            "Epoch 57/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1898 - mse: 0.1898\n",
            "Epoch 58/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1836 - mse: 0.1836\n",
            "Epoch 59/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1870 - mse: 0.1870\n",
            "Epoch 60/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1865 - mse: 0.1865\n",
            "Epoch 61/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1911 - mse: 0.1911\n",
            "Epoch 62/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1882 - mse: 0.1882\n",
            "Epoch 63/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1734 - mse: 0.1734\n",
            "Epoch 64/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1846 - mse: 0.1846\n",
            "Epoch 65/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1902 - mse: 0.1902\n",
            "Epoch 66/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1719 - mse: 0.1719\n",
            "Epoch 67/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1870 - mse: 0.1870\n",
            "Epoch 68/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1729 - mse: 0.1729\n",
            "Epoch 69/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1786 - mse: 0.1786\n",
            "Epoch 70/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1720 - mse: 0.1720\n",
            "Epoch 71/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1725 - mse: 0.1725\n",
            "Epoch 72/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1865 - mse: 0.1865\n",
            "Epoch 73/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2336 - mse: 0.2336\n",
            "Epoch 74/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2690 - mse: 0.2690\n",
            "Epoch 75/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2470 - mse: 0.2470\n",
            "Epoch 76/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2427 - mse: 0.2427\n",
            "Epoch 77/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2411 - mse: 0.2411\n",
            "Epoch 78/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2385 - mse: 0.2385\n",
            "Epoch 79/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2312 - mse: 0.2312\n",
            "Epoch 80/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2126 - mse: 0.2126\n",
            "Epoch 81/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1877 - mse: 0.1877\n",
            "Epoch 82/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1776 - mse: 0.1776\n",
            "Epoch 83/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364\n",
            "Epoch 84/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2279 - mse: 0.2279\n",
            "Epoch 85/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1942 - mse: 0.1942\n",
            "Epoch 86/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1765 - mse: 0.1765\n",
            "Epoch 87/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1664 - mse: 0.1664\n",
            "Epoch 88/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1607 - mse: 0.1607\n",
            "Epoch 89/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1742 - mse: 0.1742\n",
            "Epoch 90/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2200 - mse: 0.2200\n",
            "Epoch 91/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2147 - mse: 0.2147\n",
            "Epoch 92/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1889 - mse: 0.1889\n",
            "Epoch 93/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1762 - mse: 0.1762\n",
            "Epoch 94/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2002 - mse: 0.2002\n",
            "Epoch 95/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1816 - mse: 0.1816\n",
            "Epoch 96/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2158 - mse: 0.2158\n",
            "Epoch 97/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1883 - mse: 0.1883\n",
            "Epoch 98/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1766 - mse: 0.1766\n",
            "Epoch 99/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.2151 - mse: 0.2151\n",
            "Epoch 100/100\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1843 - mse: 0.1843\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16c2e7f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Best MSE is:  0.3434989786211655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1xrCoHTEYc_"
      },
      "source": [
        "**Evaluating keras baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L76awYlQKivc"
      },
      "source": [
        "x = np.arange(1, 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "ZBP4VRIeKHN_",
        "outputId": "2b82a014-d10b-44ed-f22b-16f18f0810f7"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "  \n",
        "# plotting the points  \n",
        "plt.plot(x, history.history[\"loss\"]) \n",
        "  \n",
        "# naming the x axis \n",
        "plt.xlabel('100 epochs') \n",
        "# naming the y axis \n",
        "plt.ylabel('Mean Squared Error (mse)') \n",
        "\n",
        "# giving a title to my graph \n",
        "plt.title('MSE variation in learning phase on train data') \n",
        "plt.yscale('log')\n",
        "# function to show the plot \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEcCAYAAADUX4MJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hc1bXw4d8UdUuWLcu9twUu9N4MGEIJhFwgtAAhCUngJiHtply+FJKb5JKEkITADaSQEIqBhBYwBDDF2GCMbdyB5W7Lstzkpt5mvj/2kTQaqxzZGo88s97n0SPNOWfmrD0zmjW7nL0D0WgUY4wxpivBZAdgjDHm8GAJwxhjjC+WMIwxxvhiCcMYY4wvljCMMcb4YgnDGGOML5YwTLtEZKSIVIpI6ADvf7uI/DkBcX1aRF45wPveISKP9HRMPs+9UkTOTsJ53xSRmw/1eXsz7309tocea4OInNcTj3U4CCc7gFQlIhuAocBQVd0Zs30xcAwwRlU3iMhw4HfANCADKAHuUtW/ichoYD1QFffwn1fVJxIZv6puAvr4Odb7IHxEVYfH3P/nCYrrUeDRRDx2Iqnq5GTHcLhr7312IFTV1/u6p4lIFJigqmuScf6eYAkjsdYD1wK/BxCRqUBu3DEPA0uBUUAdMBUYHHdMoao2JjbUViISPpTnO9zZ89V72GuRWJYwEuth4Ea8hAF8Bvg78NOYY04EvqGqzbWIxQdyIhG5Gvi2qp4Qs+0bwDmq+gkR+bh33nHAXuAvqnqHd9xoXHK7GfgRsEFEbvS2Zahqo4h8FvgOMBzYAfxCVR8QkTzgJSBLRCq9U08EvgiMV9XrvXN8AvhfYBiwBLhVVT/09m0A7vWeq1HAv4HPqGptO+W8CbhZVc/wbkeBW4FvAcW42sdXVLXLKQxE5BTgbmASsBH4mqq+6e1rt7zevrOBR3Cv6zeAV0Vkrfc4tcB/AJu8MiyMKePNqjpLRO7o4tjjgL8A473nIgKsVtXvd/B8fAH3vrkBKAO+rKqvxRw2SkTeBo4C5gHXNdd6ReQfwJlADu6Ly62qutLbdzFwFzAC2Af8RlXv8vZdgns/jQY+AG5R1WUdPM+n4WrRE4FV3vP8jrfvTWAOcG578cU8Rmfvsynec/kJ4Jsissw735FADfAU8E1Vrfceq+Wbvoj8DVeDHw2c5ZXlOlVd20FZbvDK3Qf33ondd1JH5xWRt7zDlnrn/zzwCu4z4mTcZ/Hb3vO4ub1z9wbWh5FY7wIFInKk1xdwDe6DJv6Y+0TkGhEZeRDneh4QEZkQs+064DHv7yrcB3Ih8HHgVhH5ZNxjTMO92S9o5/G3A5cABcBngd+IyHFeorsI2KKqfbyfLbF3FJGJwAzg67gP9ReB50UkM+awq4ALgTG4D46bulH2S3CJ9yjvcdqLvw0RGQbMxP3z9wf+C3hKRIo7K2/MQwz27jcK96EF7gPrcdxz/C9cEuxIu8d6z8kzwN+8x5+BSyqdORlYCwzAJfynRaR/zP7rvDIMBDK9sjZ7CZjg7Xufts19fwG+pKr5uA/l170YjwUeBL4EFAEPAP8Skaz4wLw4ZgL3eMfeDcwUkSKf8QHQxfvsMuCfuOfyUaAJl8gHAKcC04H/bOd5a3YN8GOgH7AG+Fl7B4nIJOAPuMQ81CtPbPNYh+dV1bO8Y472Yn8C9/n7V9x7aCQuyXT2nkk6q2EkXnMtYzbwIVAat/9TwHeBHwBHiMhy4AuquiDmmJ0iEnufU5u/nTdT1WoReQ7XBPYTL3Ecgfswovmbs2eZiMzAJYhnY7bf0VzTiTsfqjoz5uZsr+P5TNyHTFeuBmaq6qveY98FfA04DWiO657mDwAReR7Xz+PXnaq6B9gjIm949/13F/e5HnhRVV/0br8qIguBi4GHfJQ3AvxIVeu8mAHmNj+eiDyMS5Ad6ejYU3D/l/d4taSnReS9LsqyHfitd/wTIvIt3JeCh739f1XVVd65nsQlKwBU9cHmv72az24R6auqe4EGYJKILFXV3cBu79AvAg+o6nzv9kMicrsX++y42D6Oqx01xzJDRG4DLsUlxU7j82meqja/j2uARTH7NojIA7j3+m87uP8zqvqed/5Hias5xLgSeEFV3/KO/QHwleadqtqt86pqOa4Wgvd4PwPe6ODcvYIljMR7GHgL98357/E7vX/E7wHfE5EBuCaAZ73O8GYDfLbLPgb8GvgJ7lvbs6paDSAiJwN34r4pZgJZwD/i7l/S0QOLyEW4b68Tcd+McoHlPmIC921sY/MNVY2ISAmuearZ1pi/q737+BV/Xz+dmqOAT4nIpTHbMvD+YX2Ud0c7TWbxcWR30qbe7rG4cpfGNal1+Lp44o/fSNvnr93nx6v1/gz3paUYlwTBfUPeC1wBfB+402vm+Z6qzsM9d58Rka/GPG4m7b9mbV77mPg6e+272ynd5vnxarR3AyfgXrcwbZNIPL/nHxp7LlWtEpHyAz2viOQCv8HVrPt5m/NFJKSqTZ3EmzTWJJVgqroR1xdwMfB0F8fuxCWMobjmiO56FSgWkWNwNY3HYvY9hqttjFDVvsD9QCDu/u22+3tNDU95sQ1S1UJcs1Kgs/vF2IL7kGl+vACuXTy+tnUolQAPq2phzE+eqt7po7zQdZkPVBkwzHuOmo3o4j7xx4/EPedduQ7XnHMe0BfXjg9eOVV1gapehmsqehZ40ttfAvws7rnLVdUZ7ZyjzWsfE9+BvPYdPefx2/8AfITrpygAbmf/9/qBKCPmtfA+8GOb1rp73m8BApzsHd/cbNUTsSaE1TAOjc8D/bxvJG2ecxH5Ba4W8hGu4/FWYI2qlotIfndOoqoNXifmr3AJ59WY3fnALlWt9TrnrsN1uvnRXCPZATR6374/Bqzw9m8DimKaMuI9iatBTcfVtr6GGxH2TnfK18MeARaIyAXALFzt4hRcG/ZeOi9vIs3DtYV/RUT+gGvSOYnWprv2DARuE5H/Az6J64d6sZPjm+XjXody3DfilqHQXl/Kp3BNMHtFZB+tNZA/Ac+IyCzgPe++ZwNvqWpF3DleBH4vItfh3gdX4Dr8X/ARX7yu3mex5doHVIrIEbj/qR0HcL54/wTmi8gZuHL/hLZfurs67zZgLO491nx8Da4ptT+uRturWQ3jEFDVtc0jYNqRi+vk3AOsw30bi2/D3SPuYqPmn292crrHcN8Y/xHXFPKfuL6NCuCHtH5b9BN/BXCbd5/duGTzr5j9H+E6Z9eJyB4RGRp3f8X1Gfwe2Ilrv760edRKMqhqCe7b9e24f+oS4NtAsKvyJjiueuBy3JeMPbjn7QXcB3tH5uM6rnfimpiu9NrHu/J3XPNQKW500Ltx+2/AtcXvA24BPu3FuBA3Mute3POzhg4GKXhxXIL7Nl2OG3l2SfwoKD+6ep/F+C/ca1aBS249cs2SN3rsy7j/sTJc2WNHNHV13jtw/T17ROQqXN9GDu51e5eu+92SLmALKBnTu4nIfOB+Vf1rO/tuImaYsTGJZE1SxvQyIjINUNw3z0/jhgv3+m+fJvVZwjCm9xFcc1gerpnySlUtS25IxliTlDHGGJ+s09sYY4wvqdoklYWbKqIMN0TRGGNM10LAEGAB7YzMS9WEcSJuQjNjjDHddyYwN35jqiaMMoDdu6uIRPz10RQV9aG8vLLrA1NMOpY7HcsM6VnudCwzHHi5g8EA/frlgfcZGi9VE0YTQCQS9Z0wmo9PR+lY7nQsM6RnudOxzHDQ5W63Kd86vY0xxvhiCcMYY4wvljCMMcb4YgnDGGOML5YwjDHG+GIJwxhjjC+WMOKsL9vH9+6fR3WtnxVRjTEmfVjCiLNjTw3b99SwuyJ+uWZjjElvljDiZITdU9LYlJ4X+xhjTEcsYcTJCLmnpKEx0sWRxhiTXixhxGmuYTQ02iS3xhgTyxJGnHBzwrAmKWOMacMSRhxrkjLGmPZZwojT0iTVZE1SxhgTyxJGHKthGGNM+yxhxLFhtcYY0z5LGHFaOr2thmGMMW306hX3ROQM4C4gAjylqr9O9Dlbm6SsD8MYY2L19hrGOuAsVT0NuEREchN9wrA1SRljTLt6dQ1DVbfE3GzC1TQSKhgIEAoGrEnKGGPiHLKEISJ3AVcAo4GpqrrC2z4ReAgoAsqBG1V1ddx9zwfWquohmREwIxy0hGGMMXEOZQ3jWeB3wJy47fcD96nqIyJyPfAAcG7zThEZDvw38InunrCoqE+3ji8uzgcgKzNEODPUcjvVpUs5Y6VjmSE9y52OZYbElPuQJQxVnQsgIi3bRGQgcBxwvrdpBnCviBSr6g4RyQL+BtyqqpXdPWd5eSWRiL++iOLifHbsqABcs1RFRV3L7VQWW+50kY5lhvQsdzqWGQ683MFgoNMv2snu9B4BlKpqE4D3e4u3HeA6YBLwgIi8KSLDDkVQGeEgDU3WJGWMMbF6e6f3X4G/HurzWh+GMcbsL9k1jBJgmIiEALzfQ73tSZMRCtJoNQxjjGkjqQlDVbcDS4BrvU3XAotVdUfyonLXYlgNwxhj2jpkCUNE7hGRzcBwYJaIrPR23QJ8VURWAV/1bidVRsgShjHGxPPVhyEiI4CjgUJgD7BUVbvVbKSqtwG3tbP9I+Dk7jxWomWEg1TXNSY7DGOM6VU6TBgikgF8yfsZC6wBKoB8YLyIrMddQ/FHVa0/BLEeMhmhII1WwzDGmDY6q2EsBV7HJYz5zUNfoaVz+iTg08BiYHIigzzUbJSUMcbsr7OEcbbXKb0fL3nMA+aJSHFCIkuisF2HYYwx++mw07u9ZCEiQREZEndcUkc0JYJ1ehtjzP58jZISkUIReQyoxfVlICKfEJGfJjK4ZLErvY0xZn9+h9XeD+wFRgHNHdzzgKsTEVSyZYSt09sYY+L5TRjTgdtUtQyIQktT1MBEBZZMGaEgTZGo74kLjTEmHfhNGHuBAbEbRGQkUNbjEfUCLet6W7OUMca08Jsw/gw8JSLnAEERORW36NH9CYssiVrX9baEYYwxzfzOVvsLoAa4D8gAHsQtdPS7BMWVVBkt63pbwjDGmGa+EoaqRnHJISUTRLyw1TCMMWY/fueSOgfYoKrrRWQwrsYRAf5bVbcmMsBkaK5hWMIwxphWfvsw/g9onhrkblyzVAT4YyKCSjZrkjLGmP357cMYpqqbRCQMXEDr9RhbEhZZElmTlDHG7M9vDWOfiAwCpgEfqGqltz0jMWEllzVJGWPM/vzWMH4PLAAyga97204HPkpEUMlmTVLGGLM/XzUMVf0FcB5wuqo+7m0uBW5OVGDJZNdhGGPM/vzWMFDVVZ3dTiV2pbcxxuzP77Dao4HfAMcAfbzNASCqqpkJii1prA/DGGP257eGMQN4Crcmd03iwukdWpqkrIZhjDEt/CaMwcAPvSu+U57VMIwxZn9+h9U+BFyXyEB6k+Yahq2JYYwxrfzWMO7Erd99O7AtdoeqntvjUSVZOBwArEnKGGNi+U0Y/wTWA8+QBn0YoWCQYCBgTVLGGBPDb8I4BihS1fouj0wRGeGgJQxjjInhtw9jDjApkYH0NhnhoF3pbYwxMfzWMNYDr4jIM+zfh/HDHo+qFwiHrEnKGGNi+U0YucBM3FxSI2K2p+ww24xw0Dq9jTEmht8V9z6b6EB6m4xwyGoYxhgTo8M+DG868y75Pe5wkxEK2nUYxhgTo7MaxusiMht4GJivqi2fniISBE4CbgTOAqYkNMokCIcD1iRljDExOksYxwJfBP4EjBGRdUAFkA+MAdYAD9C6PkZKyQjZsFpjjInVYcLwrrm4F7hXREYAU4FCYDewTFVLD02IyZERDlFXkzaXnRhjTJf8dnqXACUJjqVXsWG1xhjTlt8L99KOXeltjDFtWcLogF3pbYwxbVnC6IB1ehtjTFtd9mGISAh4DbhAVesSH1LvELYrvY0xpo0uaxiq2oQbRptWtRHrwzDGmLb8ziX1Y+APIvIjYDMxc0jFXtCXSjJCQRqbokSjUQKBQLLDMcaYpPObMP7s/b4hZlsAlzhCPRpRL9G8rndjU4SMcEoW0RhjusVvwhiT0Ch6oeZ1vRsaLWEYYwz4v3BvI7TMITUI2JaqTVHNmmsYDU0pO4O7McZ0i6+ObBEpEJG/A7VAKVAjIg+JSN+ERpdE4ZYaRlOSIzHGmN7B78ine4A83Ky0Obh5pXK97SmppYZhI6WMMQbw34dxITBWVau926tE5LPA2sSElXytnd7WJGWMMeC/hlELFMdtGwCk7IV84ZDVMIwxJlZ3htW+KiJ3AxuBUcA3gD8mKrBka22Ssj4MY4wB/6OkfioiW4DrgKHAFuCXwIMJjC2pWkdJWQ3DGGOg+3NJpWyCiNfcJNXYaH0YxhgD3ZtLKq3mx7AahjHGtNWduaTuT6u5pKwPwxhj2rC5pDrQPDWIDas1xhjHb8KYADQmMpDeJmwX7hljTBt+O71XAIXptIBShl2HYYwxbfjt9F4FFCU+nN7DOr2NMaYtv01SjwIviMjv2L/T+/VEBAYgIv2BVwFR1T6JOk97QsEAAayGYYwxzfwmjFu933fEbY8CY3ssmv1VAOcDTybwHO0KBAJkhIM0WsIwxhjA/5XeSVlASVUbgF0ikozT27rexhgTo9OEISKDVXVrJ/uPV9VFfk4kIncBVwCjgamqusLbPhF4CNdHUg7cqKqr/YWfWOFQ0PowjDHG01Wn96rYGyIS/0H+RjfO9SxwFm7ywlj3A/ep6kTgPuCBbjxmQlkNwxhjWnXVJBU/HciALvZ3SFXnAsQ2L4nIQOA4XD8FwAzgXhEpVtUdfh+7I0VF3esnLy7Ob3M7OytMMBzcb3uqSfXytScdywzpWe50LDMkptxdJYz4y5y7ut1dI4BSb+guqtrkzYo7AtgBICKzgGO9319vbsryo7y8kkjEX4jFxfns2FHRZlsQqKqq3297Kmmv3KkuHcsM6VnudCwzHHi5g8FAp1+0/Y6SShpVPS9Z5w6HrQ/DGGOadZUwckXkrZjb+TG3A7j1vQ9GCTBMREJe7SKEW2+j5CAft0dkhKwPwxhjmnWVMD4fd/svcbf/zEFQ1e0isgS4FnjE+724J/ovekJGOEh1XVpNoWWMMR3qNGGo6kM9dSIRuQe4HBgMzBKRclWdDNwCPCQiPwR2Azf21DkPVthqGMYY0+KQ9WGo6m3Abe1s/wg4+VDF0R02rNYYY1p1OflgOrOEYYwxrSxhdCIcCtJoo6SMMQawhNEpq2EYY0yrDvswROQnfh5AVX/Yc+H0Lhl2HYYxxrTorNN7RMzf2biJAxfg5oIaCZwEPJW40JIvI+SmN49GowQCvmdBMcaYlNRhwlDVzzb/LSKPA9eq6lMx2y4HPpXY8JIrHA4SBZoiUcIhSxjGmPTmtw/jItxss7H+BVzcs+H0LrautzHGtPKbMNYAX47bdiuwtmfD6V1sXW9jjGnl98K9m4FnROQ7QCkwDGjEXbmdspoThi3Taowx/pdoXSwiE4BTcJMDlgHzvCVUU5Y1SRljTKsDug5DVd8CMkUkr4fj6VWsScoYY1r5ShgiMhW3XOufaJ2xdhrwYILi6hXCVsMwxpgWfmsYfwB+qKpHAM3NULOBMxISVS+RlRkCoK6+KcmRGGNM8vlNGJNx61WAtyyrqlZx8Aso9Wq5Wa6Lx9bEMMYY/wljA3B87AYROQk33DZl5WZ7CaPWEoYxxvgdVvsDYKaI3I/r7P5v3MJHX0hYZL1AS8KwGoYxxvirYajqC8CFQDGu72IUcLmqvpLA2JIuJ7O5hpHSo4eNMcaXLmsYIhLCjZCapKr/mfiQeo9gMEBOVshqGMYYg48ahqo2AU24GWvTTm5WmBrrwzDGGN99GL8FnhSRnwOb8UZKAajqukQE1lvkZGVYDcMYY/CfMO71fp8ftz0KhHounN4nNytko6SMMQb/c0ml7VKuudkZ7NpXm+wwjDEm6dI2EfiVkxW2JiljjMFnDUNEwsB/4uaPGgC0LD+nqmclJrTeITc7bE1SxhiD/xrGb4AvAW/hrvh+ChgIvJ6guHqN3KwwNXWNRKLRrg82xpgU5jdhXA5cpKq/Axq9358EzklYZL1EbnaYKFBbZxMQGmPSm9+EkQuUeH/XiEiuqn4EHJuYsHqP1gkI7WpvY0x68zus9kPgROA9YCFwh4jswy3XmtLaTEDYN8nBGGNMEvlNGF/DXe0N8E3c+hj5wBcTEVRv0lzDqLGRUsaYNOf3OowFMX+vBs5LWES9TG52BmBTnBtjjN9hted2tE9VU3qkVI5NcW6MMYD/Jqm/xN0uBjJx80qN7dGIehlbdc8YYxy/TVJjYm97U55/H6hIRFC9SU6WmyrLZqw1xqS7A5oaxJvy/GfAd3o2nN4nFAySlWlrYhhjzMHMJXU+EOmpQHqz3CybHsQYY/x2epcQswYG7kK+bNz8UikvN9smIDTGGL+d3tfH3a4CVqnqvh6Op1dyNQy70tsYk978dnrPTnQgvVluVpjdlXXJDsMYY5LKb5PUw7RtkmqXqt540BH1QrnZYUp3ViU7DGOMSSq/nd57cLPThnDXXgSBy7zta2N+UlJuVoZNDWKMSXt++zAmAh9X1TnNG0TkDOAHqnpBQiLrRXK8Tu9INEowEOj6DsYYk4L81jBOAd6N2zYfOLVnw+mdcrPCRKNQV29rYhhj0pffhLEY+LmI5AB4v38GLElUYL1J8xTn1ixljElnfhPGTcDpwF4R2QbsBc4AUrKTO17LfFJ28Z4xJo35HVa7AThNREYAQ4EyVd2UyMB6E5ux1hhjujk1iKqWAAXAFSKSFv0XYDUMY4yBLhKGiMwQkZtjbn8HeAG4DpglIjckOL5eoWWZVlvX2xiTxrqqYZwO/AtARILAt4HrVPVE4ErgvxIbXu9gNQxjjOk6YRSq6nbv72NxEw4+693+NzAqUYH1Jjm2iJIxxnSZMHaKyGjv73OAed5aGAB5QFpcmBAOBcnKCFkNwxiT1roaJfVnYKaIvIwbQvvVmH1nAR8mKrDexqY4N8aku05rGKr6c+CXQAbwNVWdEbO7GPh1AmPrVXKzwrZMqzEmrXV5HYaqPgQ81MH2tJFjNQxjTJo7mCVa00puliUMY0x6s4ThU262NUkZY9KbJQyfcqyGYYxJc5YwfHLrejcSjXa58KAxxqQkv0u09sdd1X0M0Cd2n6qelYC4Ys/9e++8L3mjtpIiNztMJBqlrqGJ7Ey/604ZY0zq8PvJ9xiQBTwJVCcunLZE5ASgUVXPFJF/isggVd12qM4fK3Z6EEsYxph05PeT7zSgWFXrEhlMO04GXvf+ng0cD7x4iGMAIDc7A3DTg/RPRgDGGJNkfhPGMmA4sPZATyQidwFXAKOBqaq6wts+EXedRxFQDtyoqqu9uxUCK7y/K7zbSWETEBpj0p3fhPE68G8R+SuwNXaHqj7o8zGeBX4HzInbfj9wn6o+IiLXAw8A53r79uDW3wDI5yAS1sHKz3U1jK27qpk4Iml5yxhjksZvwjgT2AycH7c9CvhKGKo6F0BEWraJyEDguJjHnQHcKyLFqroDeA+4FngeN3fVkz7jBaCoqE/XB8UoLs7vcN+AAX0YOTif2Uu3cPn0iQQCgW49dm/WWblTVTqWGdKz3OlYZkhMuf0u0XpOj5/ZGQGUNs+Aq6pNIrLF275DVReIyE0iMgd4ubsd3uXllUQi/obBFhfns2NHRafHTD92GH996SPmLNzEkaNToyfDT7lTTTqWGdKz3OlYZjjwcgeDgU6/aHd7uI+IBICWr9eqGul2VN2gql9O5ON3xymTB/HU7LW8vKAkZRKGMcb45evCPREZJiLPiEg50Ag0xPwcjBJgmIiEvPOEgKHe9l4nIxzinOOGs2xtOWXlVckOxxhjDim/V3rfD9QD04FKXL/Dv4BbDubk3mp+S3D9FHi/F3v9F73SOccOIxwK8uqCXpnTjDEmYfwmjNOAz6nqEiCqqkuBzwPf8nsiEblHRDbjhufOEpGV3q5bgK+KyCrcAk0HlYQSrSAvk9OmDOLtFVupqK5PdjjGGHPI+O3DaMI1RQHsEZFiYB8wzO+JVPU24LZ2tn+Eu0DvsDH9+BG8tbSMRat2cPYxvp8CY4w5rPmtYcwHLvb+fhl4AngaWJiIoHq74cV55GWH2VCWfqMvjDHpy28N4wZak8vXcU1R+cBvExFUbxcIBBg9OJ8NW/clOxRjjDlk/F6HsSfm7xrgpwmL6DAxekgB/56/iYbGJjLCoWSHY4wxCed3evMs4Ie4UUxFqtpXRD4GTFTVexMZYG81enA+TZEoJdurGDu0oOs7GGPMYc5vH8ZvgCnAp3HTgQCsBG5NRFCHg9GDXZKwZiljTLrwmzD+A7hOVecBEQBVLaUbo6RSTf+CLPJzM6zj2xiTNvwmjHrimq+8obXlPR7RYSIQCDDKOr6NMWnEb8L4B/CQiIwBEJEhwL3A44kK7HAwenABW3ZWU9fQlOxQjDEm4fwmjNuB9cBy3CJGq4EtwI8TFNdhYczgfCLRKCXbK5MdijHGJJzfYbX1wDeAb3hNUTtV1d+84Sls9BCv47tsH+OH9T1k521sihAO+c31UFnTQF52OKXW8DDGHHqdJgwRGdnBrhHNCyGp6qaeDupwUdgnk755mWzYeug6vt9eXsYjr67ifz53EgMKc7o8vqy8ih89uIBPnTOO808YcQgiNMakqq6+pm7ANUWt9/6O/1mfoLgOC61XfB+ahNHYFOHZOeupq29i1qLNvu7z1Ox1NDZFmDlvI/XW12KMOQhdJYyluP6K7wOjgIy4n8yERncYGDU4n7KdVdTWN3Z98EF6Z8VWyvfVMrh/Lm8t3UJ1bes5I5EoKzfsorGpdT2rtVv28v6qHRw1roh9VfW8tXRLy77q2kZ+/vAi/vVW0pZJN8YcZjpNGKp6LHAl0B94G3gRuAbIVNWm5qVV09noIQVEgVcWlPDPN9dyzz+X8cGGXT1+nsamCC+8s4ExQ/L5wqWTqK1vYs6y1gTw7Nx1/PrxJfzfMytoaIwQjUZ56s21FORmcMtlk5kwvC8vzd/Usu9v//6INaV7eWjmB5Tvre3xeI0xqafLnlNVXaGq3wZGA3cDlwBlInJcgnylYwkAABhgSURBVGM7LIwZUkAgAM/OWc/L723igw27eOatdQf9uPuq61m5YReRqBtb8M6KrezcW8snTh/DmCEFTBxRyKyFJTRFInywYRcz39nIqMH5LFmzk98/vYz3V+3ko017uPT0MWRnhrn09NHsrqjj7RVlvLm4lIUfbee844cD8NTs1lpGQ2OE+59b0WabMcZA99b0ngBMA04FFgO7ExLRYaZvXia3X3884VCQoQPyeOP9zTz++hpKtlcyYmDHi6l3JhKJcu/Ty1mzeS9DinK5+JRRvPDOBkYPzueocUUAXHDSCH7/1HLeeL+UmfM2Mrgol+9ddxzzP9zGQy99xMp1uxjQN5tpxwwFYPLo/owZUsBzc9dTVdPA1LFFXHPeBIr65fLErFWce/xwxg4p4I/Pr2SR7iAYCDDtmKEM6Nt1x7oxJj10WsMQkf4i8mUReQ94Frc861mqeo6qpnWHd6xxw/oyanA+GeEgp00dQjgUZPaS0gN+vNcWbWbN5r1MP244oWCAv8z8sKV20Tw09ujxAxjYL4fHZq2mqraRWy6bQlZmiLOOHsrNl0wiHA5y1TnjW4bfBgIBLj1tNHsr68nPzeTmS44kGAhwxbkT6Nsnk8dfW80jryiLdAcXnTySQABefs+WoTXGtOqqhrEFNxLqYeBdb9t4ERnffICqvp6g2A5LfXIyOOGIYuat3Mqnzh5PVmb3pj7fvruap2avZerYIq47fwJRYOmanWzdVc3R44tajgsGAlxw0kgeflm5dvr4NrWZU6cM5sQjB+53rcbR44u48uxxTBnTn/xcN14hJyvMldPG8ZeZH7Juyz4+fuoorpg2jorqBuYs3cKlp4+mIDftxzYYY+g6YWwFsoEveD/xosDYng7qcHf2McN4d+U23vtwG2cePdT3/SLRKH998SNCoQCfuVAIBAIEgGMnFHdwnqFMHN6XoQPy9tvX3oV9gUCAi08Ztd/2U6cMZvHqnQzom83lZ7mX86JTRvL28jJmLdzcss0Yk946TRiqOvoQxZFSJgzvy5CiXGYv3eIrYeyuqGNVyR4Wr96BluzhpouOoH9Bdpf3CwQCDCs+sH6SWMFAgK9cPrXNtiFFeRw3sZjXF23mopNHUtfQxFtLt1DfEOG8E4ZT2CcLcJ3kby4ppXRHJVefO4GcrO50ixljDif2350AgUCAaccM4/HXVrNpWwUjB+W3e1xZeRUPv6x8tMktaJiVGeLsY4dx5lFDDmW4Hbr41FEsWrWDXzz6PqU7q2iKRAkGAsxaWMK5xw9nSFEuz7+9gZ3esNwNWyv4xlXH0DfPmrCMSUWWMBLktCmDeWr2Wu5+ciknykBOPHJgSz9DUyTKrIUlzJy3kezMEFdMG8uk0f0ZOagPoaD/OaISbcyQAo4aV+Q64I8fzjnHDiMQgOfmrufl+ZuIAiMH9eGbFx5NNAr3PbOc/31kEd+6+hgyM0Ls2F1DRXU9g4tyGdgvp1eVzRjTfYFoNCXnEBwNrC8vryQS8Ve+4uJ8duzo2Sk+Pty4m9cXbWbZunIaGiP77T918iCuPncCBUn8Rt5VuZuvHI/vEyndWcWeijqOHN2PoDdya03pXn73j6VU1e5/1XtGOMjg/rlkZgQJBYNkZYS4+JSRyMh+PVgafxLxWh8O0rHc6VhmOPByB4MBior6AIzBTf/UhtUwEujIUf04clQ/auoaWba2nN0VdS37xgzJT8qHZXd1NCvusAF5DIvrbB8/rC+333A876zYSt+8TAb2yyEvJ4Ot5dVs3lHJ1vJqGpoiRCJRNu+o5JePLebiU0dx2RljujX7rjEmOSxhHAI5WWFOnjQo2WEcEkOK8rhi2rg228YN3X/q99r6RmbMWs3MeRtZuX4XV0wb16a2YozpfSxhmKTIzgzz2YuPZOrYIh5+Rfn1E0soKsjm9KmDGTogj1AwSEY4yPhhBeRmZyQ7XGMMljBMkp1wxECOHl/E+6t2MmfZFv719oY2+3Ozwlx86iimHz+crIzuXQRpjOlZljBM0mWEQ5w8aRAnTxrEvqp6KmoaaGyMUFXb0DIL8KsLSzhiZD8CAXfdyOQx/Tll0iBfqwg2NDaxr6qBor5dX9tijOmYJQzTqxTkZbYZNTZpdH9Wlezh+bfXs6FsH9Eo1DU08c6KrSxfV84NHxNyssKsKtnDc3PXE41GueWTU1qmM6mubeDXTyxl07YKbrvyKKaOLero1MaYLljCML3exBGFfOuaY1tuRyJRZr67kWfnrGP9ln0M7JfL8nXlFORlUlPnFob65lVHk5udwa+fWMLm7ZUM6JvNvU8v55tXHU1xsbuQsrKmgS07q5g4ojBZRTPmsGIJwxx2gkE38+7E4X354/MfsG7LXq48exzTjxtOyY5K7vnnMn7+8CIK8rLYuquKr1w+lTFDC/jFo+/z238uIxIMMn95Ge+u3Ep9Y4Rrzh3Px05qu3x9ZU0DfXKss92YWHbhnscu8Dk81XnrlMd2iJeVV/GbJ5eyp7Ker1w+tWUNkd0Vddz56CJ27KklMxzklMmD2VdVz9I1O7n1k1M44YiBNDQ28fhra3hjcSlXnzueC2ISSU1dI8/NXc+pkwczanDrdC+NTRGeeH0NA/pmM/344W2uKamqbSBAgNzs5H83O9xf6wORjmUGu3DPmHa1N3JqSFEed3z2RCprGhjYL7dle7/8LL573XGs316FDCugT04G9Q1N3PX4Ev74/Ac0NkV4+b0SNm6rYOiAPJ54fQ2FfbI4edIgKmsa+M2TS1hfVsHby8v43vXHM2xAHpFolAdf/JB3V24DYM6yMq4/fyKZGSFeW1TCgo+2AwGOl2LOOmoIE0cW0tgUpbEpQlZGyC5YNIcVq2F47JtI+ogvc0V1PT9/eBHbdteQmxXm8x8/kilj+/PrJ5aytnQvX7h0EjPnbaSsvIprpk/g+bc3EAjA7dcfzysLS5i1cDNXTBvLsAF9eGzWqpbJGLMyQ5wxxU0kOW/lVqrr2k6Zkp+bwVXnjOe0KYN9jfbq6XKng3QsMySuhmEJw2NvrPTRXpl37KnhlfdK+NhJIygudMvSVtU2cOcjbqbezHCQr15xFJPH9Gfz9krufPR9AKrrGjnvhOFcO30CgUCAuoYm3lxcSjgU5LQpg1ume69vaOL91TvYtquGjHCQcCjIgg+3sXbLPmREIeedMJytu6rZuLWChsYIHz91NOOHt71CPhKNHtSV8M3l3l1RR05WiOzM1Gtg2FddT/neWsYMKQDS8/0NiUsYoTvuuONgY+uNCoGv19TU4zcf5uVlUV1dn9CgeqN0LHd7Zc7LzuCocUXkxVxVnhkOccz4AZTvq+X6jwlHjnJzfxXkZTJxZCFvr9jKSUcM5MYLj2j5IA+Hgowf1pexQwvICLc2N4VCQYYX9+GIkf2YMLyQccP6csZRQ+iXn8W7H2zj7RVb+XDjbhqbouzcV8usRZsp3VlFn+wwby8v47FZq5gxazW19U2MG1bQ0pRVVl7FPG/urtgr4qtrG/n3/I0EAoGW60/y8rJ4fcEmfv34Et5auoUhRbkM6u+a7KLRKGu37KO6rtH3ZJgl2ytZvGoHAwpzyIxrGmyKRNpNbpFItN3a1Pbd1WSEg4TimuhWleyhrqGpZYVIcMn3yTfW8u7KbYwZkt+SlFeV7OFXMxbzyoIS9lTWccTIQvoW5LBzVzXPv7OeF97ZSP/8rJYvBAB7K+tYpDvoX5DdpgwNjRHmf7CVPjmZvtd42bStgtr6pv0GS6wt3cv6sgqKCrJbXrc9lXW8+O5GXltUSlMkysB+OYRDQdZs3suMWat59NVVbNtVTWF+FoV9sthXVc9C3c7spVvYvquGYDBAfm4GO/fVsmLdLt5duY09lXX0y3flOND/60AgQK57rn8H7Nlvv9UwHPsmkj56qsx19U1kZgQPujmpsqaBsvIqhg3IIzc7g9r6Rl5+r4SX5m+kviFCAJgwopDCPpm89+F2+uVnceFJI1m+vpwV63YBkJkR5PIzx3LeCSNYvq6cv7+sLZNdnjJ5EFdOG8fcldt4dvZaJgzvS3VtI6U7qzh9ipuK5a1lZWzbVU0AOOe4YVwxbRw5WWF0026em7ueXfvqOP2oIUw7ZijhYJBn56zjtfc3E41CTlaI808YwalTBrN8bTnvrNjKxq0VnDZlMJ88cyxFfbPZXVHHM3PW8fbyMqaOLeLqc8czpCiPypoGnpq9ltlLtlBUkM1150/g2AnFVNU28Phrq3l7+VaCgQDTjx/OZWeMYXdlHfc/t4LSHVWEQ0FCwQCfOGM0AQL88821FBdmM3lMf954v5QBhdlMP3EUL8xdR2VNAwW5GeyrbuDsY4dxyamjeHNJKa8sKKG+IUJBbgbXTJ/AyZMG8dHG3fz9FfeBnZMV4lPnjOeso4fS0Bhh9pItzFpYQm5WmKPHD+CocUWU7qzijcWlbNzq3lNHjyvigpNGEolGeeGdDS3r3WRmBDl63AAyw0Hmf7iNpqYoBX0y2VtZT05WiOK+OWzaXkluVpgjRvVjxbpy6hsjFBVkUb6vruUx6hvcDNKBAC1fiAO45U8DAZgwrC9fv+54sg+ge8yapCxhdCody324lHl3RR1rS/cyYURhy6JUazbv5eFXlJLtlfTNy+Sc44Zx9LgBPDNnHcvWlrd8uAwdkMcNH5vIBxt289L8TTQ1RYgC048bztXTxxONwvPvrOfFeZuIRKNMHN6XM44aysZtFby+aDN9+2QyqF8uWrKHvn0yGdI/l4827SEcCpKdGaKqxn3wnjxpEK8uKGHRqh0tcY8c2IeRg/NbBgIcM2EAy9bsJBKNcoIMZOnandQ3RDhl8iCWrS2nqqaRaccMZVXJHkp3VrU0+1VUN3DRKSOpqm1k9uJS8vMyqa1rJCszxM2XTGJw/1xmzFrNkjU7AThuYjGfu/hIcrPdhZx/fuEDdu6tZfLoflxx9jiGFOXxzFvreHVBCc2fCicdOZDTpgzmubkbWF+2jyFFuZSVVzOwMIfLzhzD3GVlfLhxN2OGFFC+t4Z91Q1MHFFINBplTenelg/sYQPyOPvYYVRU1/P6+6VU1jQAUNgnkwtPHsWI4jwW6g4W6nbqGpo4c+pQzj9xOAMKc9BNe3h7eRlbdlZx2pTBnHHUELIzw1TXNjBv5TZWrt/FmKEFHDW2iBGD+rCnoo41pXvZtM1dXzRmSAHDivNcjW/1TlZt2s1nLp3MkAOY2cAShiWMTqVjuQ/3MjdFImzaVsmIgX1amjii0Sjvfbid5+au54QjBnLpaaNbmsS276nh+bnrOWnqEKaOajul/vY9NUQj0ZamKYC1W/by8MtKRXUDF540kmnHDCUzI0RZeRWvLdrM7oo6Lj19NKMHF7TcZ9O2ClZu2MXUMUUM9xYK27m3hmfnrGf+B9s4Xoq5Yto4igtz2FdVz9NvrWPO0i2MGVrAjRcIIwfl09gUYdbCzTw3dz3FhTl8/uNHtgxfXl+2j8dfW+1NWnlEyxLBAMvWlrO3qo4zpg5pU9urrW+kgSD5mW2/aq8t3cuCj7ZzyuRBLWWIRKK8sbiUl+Zv5LQpQ7jk1FFkZoSIRqPMXV7Gs3PWM3RAnrv+x7vQs6K6ng837qawTxYThvdtOXd9QxPzP9wGUVe7ywi3NnVFIlGaItE2zZWJYJ3e3TMaSxi+pGO507HM0PvKXVvfSGZGaL++jpq6RrIyQgSDBz9yrLeV+VCx6zCMMSmlo1FafjuZzaFnVw0ZY4zxxRKGMcYYXyxhGGOM8cUShjHGGF8sYRhjjPHFEoYxxhhfUnX8Wgjo9jjunhj3fThKx3KnY5khPcudjmWGAyt3zH32XzeA1L1w7wxgTrKDMMaYw9SZwNz4jamaMLKAE4EyoCnJsRhjzOEiBAwBFgB18TtTNWEYY4zpYdbpbYwxxhdLGMYYY3yxhGGMMcYXSxjGGGN8sYRhjDHGF0sYxhhjfLGEYYwxxpdUnRqkW0RkIvAQUASUAzeq6urkRtWzRKQIeBgYB9QDq4EvqeoOETkFeADIwS3LeL2qbk9WrIkgIj8C7gCmquqKVC+ziGQDvwHOA2qBear6xVR+r4vIJcD/AAHv58eq+nQqlVlE7gKuwC1DPVVVV3jbOyxjT5bfahjO/cB9qjoRuA/3QZJqosAvVVVUdSqwFrhTRILAI8CXvfK/BdyZxDh7nIgcB5wCbPRup3yZgV/iEsVE7/X+gbc9Jd/rIhLAfSG6QVWPAW4AHvJe61Qq87PAWXjv5RidlbHHyp/2CUNEBgLHATO8TTOA40SkOHlR9TxV3aWqb8ZsehcYBRwP1Kpq87wx9wNXHeLwEkZEsnD/JLfGbE71MvcBbgR+oKpRAFXdlgbv9QjQ1/u7EDc10ABSqMyqOldVS2K3dfa69vRrnvYJAxgBlKpqE4D3e4u3PSV537puBf4FjCTm24qq7gSCItI/SeH1tJ8Aj6jqhphtqV7mcbimhx+JyEIReVNEziCF3+teYrwKeE5ENuK+id9ICpc5Rmdl7NHyW8JIT78HKoF7kx1IIonIqcAJwP8lO5ZDLASMBRar6gnAd4GngT5JjSqBRCQM/DdwmaqOAi4FniSFy5wMljCgBBgmIiEA7/dQb3vK8TrNJgBXq2oE2IRrmmrePwCIqOquJIXYk6YBRwLrRWQDMBx4GRhP6pYZ3GvaiNcMoarzgZ1ADan7Xj8GGKqqbwN4v6tw/TipWuZmnX2G9ejnW9onDG9kzBLgWm/TtbhvZjuSF1ViiMjPce33n1TV5qmLFwE5XpMFwC3AP5IRX09T1TtVdaiqjlbV0cBm4ALgV6RomaGlie0N4HxoGSUzEFhF6r7XNwPDRUQARORIYBBuNGCqlhno/DOspz/fbHpzQESOwA076wfsxg070+RG1bNEZDKwAvehUeNtXq+q/yEip+FGTmTTOsR0W1ICTSCvlnGJN6w2pcssImOBB3FDKRuA/6eqL6Xye11EPg18D9f5DfAjVX02lcosIvcAlwODcbXGclWd3FkZe7L8ljCMMcb4kvZNUsYYY/yxhGGMMcYXSxjGGGN8sYRhjDHGF0sYxhhjfLGEYUyKEJG/ichPkx2HSV02vblJKyLyFeAmYCowQ1Vvits/HTdZ4UhgPnCTqjbPcpsF/AG4EqjGzf579yEL3pgksxqGSTdbgJ/iLmprw5si5GncVOD9gYXAEzGH3IGbVmUUcA7wHRG5MMHxGtNrWA3DpBVVfRpARE7AzS0V63Jgpar+wzvmDmCniByhqh8Bn8HVOHYDu0XkT7jayr/bO5eIfA74Nu6q3PeAL8bUVqLA14CvAwXAX4HvqmrEm034duALuAWe/g18VVX3evc9A7fexSSgAjeN+d+80/YTkZm4NRM+AK5T1bXeehF3A5/GXd2+Ebi2eQEeY/ywGoYxrSYDS5tvqGoVbqGpySLSDxgSu9/7e3J7DyQil+E+9C8HioE5tK5J0Ow/cLPpHgdcBnzO236T93MObtbZPngzC4vIKOAl3IzDxbhJ95bEPOY1wI9x00CsAX7mbf8YLolMxK0ZcRVuCnRjfLMahjGt+gDxk7LtBfJpnSZ7bzv72nML8L+q+iG0TPx4u4iMaq5lAL/wZsjdJSK/xU0M92dcLeBuVV3n3fe/gRUi8lngOmCWqjYnn3LafvA/o6rvefd7FFerADefVD5wBPBec1zGdIfVMIxpVYlrHopVgGv2qYy5Hb+vPaOA34nIHhHZA+zCrTM9LOaY2CmmN+Kmncb7vTFuXxg3++oIXK2nI1tj/q7GS3Sq+jqulnIfsF1E/igi8WU1plOWMIxptRI4uvmGiOThVq9b6fVblMXu9/5e2cFjlQBfUtXCmJ8cVX0n5pjYVc9G4jrk8X6PitvXCGzzHndct0sGqOo9qno8ru9jIq5/xRjfrEnKpBVvZbYwblW6kIhkA42q2gg8A/xKRK4AZgI/BJZ5Hd4Afwe+LyILcd/2vwB8toNT3Q/8j4gsUdWVItIX+Fhzh7rn2yIyH1cL+BqtzUczgO+KyEu4JrKfA0+oaqPXzHS7iFyFG9HVFxihqrH9GO2V+0TcF8T3aV1YKNLZfYyJZzUMk26+j1sP5HvA9d7f3wfwFpW5AtdRvBs4GdeJ3OxHuOagjcBs4Feq2u4IKVV9BvgF8LiI7MOtRXJR3GHP4RawWoJLUH/xtj8IPAy8BazHfbh/1XvcTcDFwLdwzVxLaFvr6UgB8CevXBtx/R6/8nE/Y1rYehjGJIE3rHaCqq5JdizG+GU1DGOMMb5YwjDGGOOLNUkZY4zxxWoYxhhjfLGEYYwxxhdLGMYYY3yxhGGMMcYXSxjGGGN8sYRhjDHGl/8PyJUVF2R3vesAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11YIMjiKVaYr"
      },
      "source": [
        "prediction_test = model.predict(X_test)\n",
        "prediction_train = model.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF94-NvqgiSy"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse=mean_squared_error(y_test, prediction_test)\n",
        "print(\"MSE is: \", mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zber-6NlXhP1"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_test = r2_score(y_test, prediction_test)\n",
        "r2_train = r2_score(y_train, prediction_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlbueDPeuWF"
      },
      "source": [
        "print(\"R2 train data: \" + str(r2_train))\n",
        "print(\"R2 test data: \" + str(r2_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BItpRWb6fIkT"
      },
      "source": [
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE_k_bafg4QA"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYVuHzV-iKz8"
      },
      "source": [
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "PDRdQ1AXe4mS",
        "outputId": "cfcfb831-5055-4481-8a1e-335fd9dd23a1"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_test, prediction_test)\n",
        "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "ax.set_xlabel('Actual')\n",
        "ax.set_ylabel('Predicted')\n",
        "#regression line\n",
        "y_test, prediction_test = y_test.reshape(-1,1), prediction_test.reshape(-1,1)\n",
        "ax.plot(y_test, LinearRegression().fit(y_test, prediction_test).predict(y_test))\n",
        "ax.set_title('R2: ' + str(r2_score(y_test, prediction_test)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}